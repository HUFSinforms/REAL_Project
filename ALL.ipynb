{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "함수호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time,datetime\n",
    "import numpy as np\n",
    "from pandas import *\n",
    "from informs import portfolio\n",
    "import class_informs as inform\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import math\n",
    "import random as ran\n",
    "from scipy.stats import truncnorm\n",
    "#import seaborn as sbn\n",
    "\n",
    "import time,datetime\n",
    "import cmath\n",
    "\n",
    "\n",
    "import re\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#timeseries data\n",
    "all_data=pd.read_csv('data/Timeseries_data_SP500.csv')\n",
    "date_list=list(set(list(all_data['DATE'])))\n",
    "for i in range(len(date_list)):\n",
    "    ak=date_list[i]\n",
    "    date_list[i]=ak[6:]+str('-')+ak[:2]+'-'+ak[3:5]\n",
    "date_list.sort()\n",
    "all_data['DATE']=pd.to_datetime(all_data['DATE'])\n",
    "all_data=all_data.rename(columns={'NAME':'name','DATE':'date','SEDOL':'sedol','SECTOR':'sector','BETA':'beta','ALPHA_SCORE':'as','BENCH_WEIGHT':'bw',\"MCAP_Q\":'mq'})\n",
    "sedol_list=all_data['sedol'].unique().tolist()\n",
    "\n",
    "\n",
    "\n",
    "dic_data = {k: v for k, v in all_data.groupby('date')}\n",
    "\n",
    "using_dic = dic_data[pd.to_datetime(date_list[0])]\n",
    "\n",
    "\n",
    "\n",
    "asset_list = []\n",
    "for i in using_dic[\"sedol\"]:\n",
    "    asset_list.append(i)\n",
    "\n",
    "\n",
    "dic_sedol_as = {using_dic[\"sedol\"][i] : using_dic[\"as\"][i] for i in using_dic.index}\n",
    "\n",
    "dic_bench = {using_dic[\"sedol\"][i] : using_dic[\"bw\"][i] for i in using_dic.index}\n",
    "\n",
    "dic_beta = {using_dic[\"sedol\"][i] : using_dic[\"beta\"][i] for i in using_dic.index}\n",
    "\n",
    "dic_sector = {using_dic[\"sector\"][i] : [] for i in using_dic.index }\n",
    "dic_MCAP = {using_dic[\"mq\"][i] : [] for i in using_dic.index}\n",
    "\n",
    "for i in using_dic.index:\n",
    "    dic_sector[using_dic[\"sector\"][i]].append(using_dic[\"sedol\"][i])\n",
    "    dic_MCAP[using_dic[\"mq\"][i]].append(using_dic[\"sedol\"][i])\n",
    "\n",
    "\n",
    "#risk:cov_mat\n",
    "def risk(date_str):\n",
    "    risk_data=pd.read_csv('data/Riskmodels/cov_mat_%s.csv'%(date_str))\n",
    "    risk_sedol=risk_data['ROW_INDEX'].unique().tolist()\n",
    "    risk_mat = np.zeros((len(risk_sedol),len(risk_sedol)))\n",
    "    risk_mat[np.triu_indices(len(risk_sedol), 0)] = list(risk_data['VALUE'])\n",
    "    irows,icols = np.triu_indices(len(risk_sedol),0)\n",
    "    risk_mat[icols,irows]=risk_mat[irows,icols]\n",
    "    return risk_data,risk_sedol,risk_mat\n",
    "risk_data,risk_sedol,risk_mat=risk(date_list[0])\n",
    "\n",
    "using_dic['index']=list(using_dic.index)\n",
    "\n",
    "bw=list(using_dic['bw'])\n",
    "bw=np.array(bw)\n",
    "\n",
    "beta=list(using_dic['beta'])\n",
    "beta=np.array(beta)\n",
    "\n",
    "alpha=list(using_dic['as'])\n",
    "alpha=np.array(alpha)\n",
    "\n",
    "\n",
    "sector_set = set(list(using_dic['sector']))\n",
    "sector_list = list(using_dic['sector'])\n",
    "\n",
    "gbs=using_dic[['sector', 'index']].apply(tuple, axis=1)\n",
    "group_by_sector = [[y[1] for y in gbs if y[0]==x] for x in sector_set]\n",
    "\n",
    "mq_list=list(using_dic['mq'])\n",
    "mq_set=set(list(using_dic['mq']))\n",
    "\n",
    "gbm=using_dic[['mq', 'index']].apply(tuple, axis=1)\n",
    "group_by_mq = [[y[1] for y in gbm if y[0]==x] for x in mq_set]\n",
    "\n",
    "nbasset=len(bw)\n",
    "nbsector=len(sector_set)\n",
    "nbmq=len(mq_set)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "as_ = dic_data[Timestamp('2007-01-03 00:00:00')]['as']\n",
    "nbasset=len(risk_sedol)\n",
    "\n",
    "def cal_obj(sol, risk_mat, as_) :\n",
    "    a = np.full((len(risk_mat[0]), len(risk_mat[0])), 5000)\n",
    "    risk_mat = risk_mat * a\n",
    "    s_rr = np.dot(sol, risk_mat)\n",
    "    s_r = np.dot(s_rr, sol)\n",
    "    s_a = np.dot(sol, as_)\n",
    "    obj = s_r+s_a\n",
    "    return obj\n",
    "\n",
    "\n",
    "\n",
    "def select_candi(sol) :\n",
    "    \n",
    "    save_sub = [0]*len(as_)\n",
    "    save_add = [0]*len(as_)\n",
    "    diff_sub = [0]*len(as_)\n",
    "    diff_add = [0]*len(as_)\n",
    "    candi = []\n",
    "    \n",
    "    for i in range(len(sol)) :\n",
    "        if(sol[i] > 0) :\n",
    "            w = sol[i]\n",
    "            save_sub[i] = w\n",
    "            diff_sub[i] = cal_obj(save_sub, risk_mat, alpha)\n",
    "            np_su = np.array(diff_sub)\n",
    "            \n",
    "            if min(np_su[np_su>0]) == diff_sub[i] :\n",
    "                for j in range(len(sol)) :\n",
    "                    if sol[j] == 0 :\n",
    "                        save_add[j] = w\n",
    "                        diff_add[j] = cal_obj(save_add, risk_mat, alpha)\n",
    "                        save_add[j] = 0\n",
    "            save_sub[i] = 0\n",
    "\n",
    "    np_ad = np.array(diff_add)\n",
    "\n",
    "    if sol[diff_sub.index((min(np_su[np_su>0])))] == sol[diff_add.index((min(np_ad[np_ad>0])))] :\n",
    "        sol[diff_add.index((min(np_ad[np_ad>min(np_ad[np_ad>0])])))] = 0.1\n",
    "    else :\n",
    "        sol[diff_add.index((min(np_ad[np_ad>0])))] = 0.1\n",
    "        \n",
    "    sol[diff_sub.index((min(np_su[np_su>0])))] = 0\n",
    "\n",
    "    for val in range(len(sol)) :\n",
    "        if sol[val] > 0. :\n",
    "            candi.append(val)\n",
    "            \n",
    "    return candi\n",
    "\n",
    "\n",
    "\n",
    "def update(sol,lim_time) :\n",
    "    start_time = time.time()\n",
    "    ex = inform.informs(10000)\n",
    "    ex.set_omega(risk_mat)\n",
    "\n",
    "    new_list = []          \n",
    "    for k in risk_sedol :\n",
    "        new_list.append(sol[k])\n",
    "\n",
    "    result_list = []\n",
    "\n",
    "    while(True):\n",
    "\n",
    "        if time.time() - start_time > lim_time:\n",
    "            break\n",
    "        con = select_candi(new_list)\n",
    "        ex.set_con(cons=con)\n",
    "        new_list2 = []\n",
    "        new_list3 = []\n",
    "        try:\n",
    "            aabbaa = ex.solve(0.01)\n",
    "\n",
    "            if aabbaa != 0:\n",
    "                aaaa = aabbaa[0]\n",
    "                bbbb= aabbaa[1]\n",
    "                for k in risk_sedol :\n",
    "                    new_list2.append(aaaa[k])\n",
    "                for k in risk_sedol :\n",
    "                    new_list3.append(bbbb[k])\n",
    "                new_list = new_list2\n",
    "\n",
    "                result_list.append(aabbaa[2])\n",
    "\n",
    "            else:\n",
    "                print(\"TE infeasible\")\n",
    "        except:\n",
    "            print(\"no solution\")\n",
    "\n",
    "\n",
    "    return result_list\n",
    "\n",
    "def sample_Z(m, n):\n",
    "    return Variable(torch.Tensor(np.random.uniform(0., 1., size=[m, n])))\n",
    "\n",
    "        \n",
    "def xavier_init(size):\n",
    "    in_dim = size[0]\n",
    "    xavier_stddev = 1. / np.sqrt(in_dim / 2.)\n",
    "    return np.random.normal(size=size, scale=xavier_stddev)\n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self,  in_dim=10, hd_dim=50, out_dim=nbasset):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        self.G_W1 = nn.Parameter(torch.from_numpy(xavier_init([in_dim, hd_dim])).float())\n",
    "        self.G_b1 = nn.Parameter(torch.from_numpy(np.zeros(shape=[hd_dim])).float())\n",
    "        \n",
    "    \n",
    "        self.G_W12 = nn.Parameter(torch.from_numpy(xavier_init([hd_dim, hd_dim])).float())\n",
    "        self.G_b12 = nn.Parameter(torch.from_numpy(np.zeros(shape=[hd_dim])).float())\n",
    "        \n",
    "        self.G_W13 = nn.Parameter(torch.from_numpy(xavier_init([hd_dim, hd_dim])).float())\n",
    "        self.G_b13 = nn.Parameter(torch.from_numpy(np.zeros(shape=[hd_dim])).float())\n",
    "\n",
    "        \n",
    "        self.G_W2 = nn.Parameter(torch.from_numpy(xavier_init([hd_dim, out_dim])).float())\n",
    "        self.G_b2 = nn.Parameter(torch.from_numpy(np.zeros(shape=[out_dim])).float())\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu( x @ self.G_W1 + self.G_b1)\n",
    "        x = F.relu( x @ self.G_W12 + self.G_b12)\n",
    "        x = F.relu( x @ self.G_W13 + self.G_b13)\n",
    "        x = x @ self.G_W2 + self.G_b2\n",
    "\n",
    "        return F.sigmoid(x*0.1)\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, in_dim=nbasset,train=False):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.tot_infs = 0.0\n",
    "        self.tot_infs_nor = 0.0\n",
    "        self.train = train\n",
    "        self.x_threshold = 0.001\n",
    "        self.inf_scale = 100.0\n",
    "        self.Zstar = 1000\n",
    "        \n",
    "        self.in_dim = in_dim\n",
    "\n",
    "        np.random.seed(0)\n",
    "        self.Omega = Variable(torch.from_numpy(risk_mat)).float()\n",
    "\n",
    "        self.card_upper = 70.\n",
    "        self.card_lower = 60.\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        tot_infs = Variable(torch.zeros(x.size()[0]))\n",
    "        x_bw = Variable(torch.from_numpy(bw).float())\n",
    "        alp = Variable(torch.Tensor(alpha).float())   \n",
    "        bet = Variable(torch.Tensor(beta).float())\n",
    " \n",
    "        # (4)\n",
    "        tot_infs += F.relu(1. - torch.sum(x,1))\n",
    "        tot_infs += F.relu(torch.sum(x,1) - 1.)\n",
    "        \n",
    "        # (5)\n",
    "        tot_infs += F.relu(torch.abs(x-x_bw)@ Variable(torch.ones(self.in_dim))-0.05)\n",
    "\n",
    "        # (6)\n",
    "        for j in range(nbsector):\n",
    "            k= (x-x_bw) @ Variable(\n",
    "                torch.Tensor([1 if i in group_by_sector[j] else 0 for i in range(self.in_dim)]).float())  #sum\n",
    "            l = torch.abs(k)\n",
    "            tot_infs += F.relu(l - 0.1)\n",
    "            \n",
    "        # (7)\n",
    "        for j in range(nbmq):\n",
    "            k = (x-x_bw) @ Variable(\n",
    "                torch.Tensor([1 if i in group_by_mq[j] else 0 for i in range(self.in_dim)]).float())  #sum\n",
    "            l = torch.abs(k)\n",
    "            tot_infs += F.relu(l - 0.1)\n",
    "            \n",
    "        # (8)\n",
    "        k = (x - x_bw)@bet\n",
    "        l = torch.abs(k)\n",
    "        tot_infs += F.relu(l - 0.1)\n",
    "        \n",
    "        # (9) lb <= card(x) <= b\n",
    "        if self.train:\n",
    "            num_non_zeros = torch.sum(torch.tanh(x / self.x_threshold), 1)\n",
    "            tot_infs += F.relu(num_non_zeros - self.card_upper) + F.relu(self.card_lower - num_non_zeros)\n",
    "        else:\n",
    "            num_non_zeros = torch.sum(x.data>self.x_threshold, 1).float()\n",
    "            tot_infs += Variable(np.maximum(num_non_zeros - self.card_upper, 0) + np.maximum(self.card_lower - num_non_zeros, 0))\n",
    "    \n",
    "        \n",
    "        # (10)\n",
    "        l = 0.5*torch.sum(torch.abs(x - x_bw))\n",
    "        tot_infs += F.relu(0.6 - l)\n",
    "        #tot_infs += F.relu(l - 1.)\n",
    "    \n",
    "        \n",
    "        # (11) a<=dQd <= b\n",
    "        dQ = (x-x_bw) @ self.Omega\n",
    "        size_x = x.size()\n",
    "        dQd = torch.bmm(dQ.view(size_x[0],1,size_x[1]), (x-x_bw).view(size_x[0],size_x[1],1)).squeeze(1).squeeze(1)\n",
    "        tot_infs += F.relu(dQd - 0.01)\n",
    "        tot_infs += F.relu(0.0025 - dQd)\n",
    "        \n",
    "        \n",
    "        # min dQd + ad (<= Zstar)\n",
    "        l = (x-x_bw)@alp\n",
    "\n",
    "        MONTH =0\n",
    "        turnover=x_bw\n",
    "        \n",
    "        if MONTH > 0 :\n",
    "            tot_infs += (F.relu(100.*dQd - 100.*l -0.5*turnover - self.Zstar))\n",
    "            self.objs = 100.*dQd - 100.*l -0.5*turnover\n",
    "        else:\n",
    "            tot_infs += (F.relu(100.*dQd - 100.*l  - self.Zstar ))\n",
    "            self.objs = 100.*dQd - 100.*l\n",
    "        \n",
    "        \n",
    "        fea_probs = F.relu(1. - F.tanh(tot_infs/self.inf_scale))  \n",
    "\n",
    "        \n",
    "        return fea_probs\n",
    "        \n",
    "\n",
    "\n",
    "def GAN(rotation):\n",
    "    X_dim = nbasset\n",
    "    HL_dim = 50\n",
    "    Z_dim = 10\n",
    "\n",
    "    G = Generator(Z_dim, HL_dim, X_dim)\n",
    "\n",
    "    sample_D = Discriminator(X_dim, train=False)\n",
    "    train_D = Discriminator(X_dim, train=True)\n",
    "\n",
    "    G_solver = optim.Adam(G.parameters(), lr=1e-3)\n",
    "\n",
    "    mb_size = 128\n",
    "\n",
    "    best_obj = 100000.0\n",
    "    best_sols = []\n",
    "\n",
    "    losses = []\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    feasible_threshold = 0.95\n",
    "\n",
    "    adaptive_inf_scale = float(nbasset)\n",
    "\n",
    "    for it in range(rotation):\n",
    "        if it % 1000 == 0:\n",
    "            sample_noise = sample_Z(128, Z_dim)\n",
    "            samples = G(sample_noise)\n",
    "\n",
    "            sample_D.Zstar = best_obj\n",
    "            sample_D.inf_scale = adaptive_inf_scale\n",
    "\n",
    "            sample_D_values = sample_D(samples).data.numpy()\n",
    "            sample_obj_values = sample_D.objs.data.numpy()\n",
    "\n",
    "            fea_sample_obj_values = sample_obj_values[sample_D_values > feasible_threshold]\n",
    "            sols = samples.data.numpy()[sample_D_values > feasible_threshold]\n",
    "\n",
    "            if len(fea_sample_obj_values > 0):\n",
    "                best_idx = np.argmin(fea_sample_obj_values)\n",
    "                if np.min(fea_sample_obj_values) < best_obj:\n",
    "                    best_obj = np.minimum(fea_sample_obj_values[best_idx], best_obj)\n",
    "                    best_sols.append(sols[best_idx])\n",
    "\n",
    "        z = Variable(torch.randn(mb_size, Z_dim))\n",
    "\n",
    "        train_D.Zstar = best_obj\n",
    "        train_D.inf_scale = adaptive_inf_scale\n",
    "\n",
    "        G_loss = -torch.mean(torch.log(train_D(G(z))))\n",
    "\n",
    "        G.zero_grad()\n",
    "        G_loss.backward()\n",
    "        G_solver.step()\n",
    "\n",
    "        \n",
    "    return best_sols, sols,fea_sample_obj_values\n",
    "\n",
    "def GAN_reulst(best_sols, sols,fea_sample_obj_values):    \n",
    "    good_sols=np.argsort(fea_sample_obj_values)[:10]\n",
    "    card_list=[list(np.where(sols[i]>0.001)[0]) for i in range(len(good_sols))]\n",
    "    card_freq=np.zeros(nbasset)\n",
    "    for i in range(len(card_list)):\n",
    "        for j in card_list[i]:\n",
    "            card_freq[j]+=1\n",
    "    best=np.argsort(sum(sols))[::-1][:len(card_freq[card_freq>len(card_list)-5])]\n",
    "    bestsol=np.where(best_sols[0]>0.001)[0]\n",
    "    return best,bestsol\n",
    "\n",
    "def initial_card(init_set,c_time=5.,gan_rot=3000.):\n",
    "    if init_set=='cplex':\n",
    "        sedol_var_list =[]\n",
    "        for i in risk_sedol:\n",
    "            sedol_var_list.append(\"d\"+str(i))\n",
    "\n",
    "        for i in risk_sedol:\n",
    "            sedol_var_list.append(\"q\"+str(i))\n",
    "\n",
    "        sedol_var_list.append(\"assum\")\n",
    "        #global alpha\n",
    "        alpha = []\n",
    "        for i in risk_sedol:\n",
    "            alpha.append(-100000.*dic_sedol_as[i])\n",
    "\n",
    "        qmat=[]\n",
    "        for i in range(len(risk_mat)):\n",
    "            qmat_1=[]\n",
    "            qmat_1.append(sedol_var_list)\n",
    "            new_risk_mat=[]\n",
    "            for j in risk_mat[i]:\n",
    "                new_risk_mat.append(10000*j)\n",
    "            for j in risk_mat[i]:\n",
    "                new_risk_mat.append(0)\n",
    "            new_risk_mat.append(0)\n",
    "            qmat_1.append(new_risk_mat)\n",
    "            qmat.append(qmat_1)\n",
    "\n",
    "        for i in range(len(risk_mat)):\n",
    "            qmat_1=[]\n",
    "            qmat_1.append(sedol_var_list)\n",
    "            new_risk_mat=[]\n",
    "            for j in risk_mat[i]:\n",
    "                new_risk_mat.append(0)\n",
    "            for j in risk_mat[i]:\n",
    "                new_risk_mat.append(0)\n",
    "            new_risk_mat.append(0)\n",
    "            qmat_1.append(new_risk_mat)\n",
    "            qmat.append(qmat_1)\n",
    "\n",
    "        for i in range(1):\n",
    "            qmat_1=[]\n",
    "            qmat_1.append(sedol_var_list)\n",
    "            new_risk_mat=[]\n",
    "            for j in risk_mat[i]:\n",
    "                new_risk_mat.append(0)\n",
    "            for j in risk_mat[i]:\n",
    "                new_risk_mat.append(0)\n",
    "            new_risk_mat.append(0)\n",
    "            qmat_1.append(new_risk_mat)\n",
    "            qmat.append(qmat_1)\n",
    "\n",
    "        q_con1 = []\n",
    "        q_con2 = []\n",
    "        q_val = []\n",
    "\n",
    "\n",
    "        for i in range(len((risk_mat[0]))):\n",
    "            for j in range(len(risk_mat[0])):\n",
    "                if j >= i:\n",
    "                    q_con1.append(i)\n",
    "                    q_con2.append(j)\n",
    "                    if i == j:\n",
    "                        ex_list = list(risk_mat[i])\n",
    "                        q_val.append(0.5*ex_list[j]*10000)\n",
    "                    else:\n",
    "                        ex_list = list(risk_mat[i])\n",
    "                        q_val.append(ex_list[j]*10000)\n",
    "\n",
    "        Q_con = []\n",
    "        Q_con.append(q_con1)\n",
    "        Q_con.append(q_con2)\n",
    "        Q_con.append(q_val)\n",
    "\n",
    "        sol = portfolio(sector=dic_sector,bench=dic_bench,asset=risk_sedol,MCAPQ=dic_MCAP,beta=dic_beta,alpha=alpha,qmat=qmat, Q_con=Q_con,multiple=10000,time_init=c_time)[0]\n",
    "\n",
    "    elif init_set=='GAN':\n",
    "\n",
    "        best_sols, sols,fea_sample_obj_values=GAN(gan_rot)\n",
    "        best,bestsol=GAN_reulst(best_sols, sols,fea_sample_obj_values)\n",
    "\n",
    "        ###code for best_sols    \n",
    "        #     sol={}\n",
    "        #     for i in range(len(risk_sedol)):\n",
    "        #         sol[risk_sedol[i]]=best_sols[0][i] \n",
    "\n",
    "        print(len(best))\n",
    "\n",
    "\n",
    "        sol={}\n",
    "        for i in range(len(risk_sedol)):\n",
    "            if i in best: sol[risk_sedol[i]]=1.\n",
    "            else: sol[risk_sedol[i]]=0.\n",
    "\n",
    "    elif init_set=='random':\n",
    "        r=list(set(list(np.random.randint(len(risk_sedol),size=70))))\n",
    "        sol={}\n",
    "        for i in range(len(risk_sedol)):\n",
    "            if i in r: sol[risk_sedol[i]]=1.\n",
    "            else: sol[risk_sedol[i]]=0.\n",
    "    return sol\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "solve!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n",
      "0\n",
      "TE :  [ 32.71884453]\n",
      "1\n",
      "TE :  [ 32.3424469]\n",
      "------objective value 변화------\n",
      "[16.341882815162325, 16.14759775956412]\n"
     ]
    }
   ],
   "source": [
    "#initial set by GAN, cplex, \n",
    "init_set='GAN'\n",
    "\n",
    "sol = initial_card(init_set,c_time=60.,gan_rot=2000)\n",
    "result = update(sol,10.)\n",
    "\n",
    "print(\"------objective value 변화------\")\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Evaluation Criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def turnover(w_dic,w_dic2):\n",
    "    pre_list = set(list(w_dic.keys()))\n",
    "\n",
    "    rotp_t0 = 0\n",
    "\n",
    "    for i in risk_sedol:\n",
    "        rotp_t0 += w_dic[i]*dic_sedol_as[i]\n",
    "\n",
    "\n",
    "\n",
    "    pre_list2 = set(list(w_dic2.keys()))\n",
    "\n",
    "    turnover = 0\n",
    "\n",
    "    add_key_1 = pre_list-pre_list2\n",
    "    add_key_2 = pre_list2-pre_list\n",
    "\n",
    "\n",
    "    for i in add_key_2:\n",
    "        w_dic.update({i:0})\n",
    "\n",
    "    for i in add_key_1:\n",
    "        w_dic2.update({i:0})\n",
    "\n",
    "    pre_list.union(pre_list2)\n",
    "\n",
    "    for i in pre_list:\n",
    "        turnover += abs(w_dic2[i]-w_dic[i])\n",
    "\n",
    "    rOTP = 0\n",
    "\n",
    "    for i in dic_sedol_as.keys():\n",
    "        rOTP += w_dic2[i]*dic_sedol_as[i]\n",
    "\n",
    "    r_Txadj_t = rOTP - turnover*0.5\n",
    "    \n",
    "    result=[]\n",
    "    result.append(turnover,rOTP,r_Txadj_t)\n",
    "    \n",
    "    print(\"turnover : \" + str(turnover))\n",
    "    print(\"r_OTP : \" + str(rOTP))\n",
    "    print(\"r_Txadj_t : \" + str(r_Txadj_t))\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "def IR_TE(result,bench_t):\n",
    "    cal1 = 1\n",
    "    cal2 = 1\n",
    "    list_std=np.array([])\n",
    "\n",
    "    for i in range(len(result)):\n",
    "        cal1 = cal1*(1+result[i])\n",
    "        cal2 = cal2*(1+bench_t[i])\n",
    "        list_std = np.append(list_std,resultp[i]-bench_t[i])\n",
    "    \n",
    "    IR = (cal1-cal2)/np.std(list_std)\n",
    "    \n",
    "    TE = math.sqrt(13)*np.std(list_std)\n",
    "    \n",
    "    result = []\n",
    "    \n",
    "    result.append(IR,TE)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def R_SR(result,bench,n):\n",
    "    R_CUM = 1\n",
    "    B_CUM = 1\n",
    "    for i in range(len(result)):\n",
    "        R_CUM = R_CUM*(1+result[t])\n",
    "        \n",
    "    for i in range(len(bench)):\n",
    "        B_CUM = B_CUM*(1+bench[t])\n",
    "    \n",
    "    R_CUM = R_CUM-1\n",
    "    \n",
    "    B_CUM = B_CUM-1\n",
    "    \n",
    "    R_ANN = (1+R_CUM)**(13/n) - 1\n",
    "    \n",
    "    B_ANN = (1+B_CUM)**(13/n) - 1\n",
    "    \n",
    "    R_EXAN = R_ANN-B_ANN\n",
    "    \n",
    "    r_t = np.array(result)\n",
    "    \n",
    "    SR = R_CUM/np.std(r_t)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
