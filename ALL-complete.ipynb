{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "함수호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time,datetime\n",
    "import numpy as np\n",
    "from pandas import *\n",
    "from informs import portfolio\n",
    "import class_informs as inform\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import math\n",
    "import random as ran\n",
    "from scipy.stats import truncnorm\n",
    "#import seaborn as sbn\n",
    "\n",
    "import time,datetime\n",
    "import cmath\n",
    "\n",
    "\n",
    "import re\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete\n"
     ]
    }
   ],
   "source": [
    "#timeseries data\n",
    "all_data=pd.read_csv('data/Timeseries_data_SP500.csv')\n",
    "\n",
    "all_data['DATE']=pd.to_datetime(all_data['DATE'])\n",
    "all_data=all_data.rename(columns={'NAME':'name','DATE':'date','SEDOL':'sedol','SECTOR':'sector','BETA':'beta','ALPHA_SCORE':'as','BENCH_WEIGHT':'bw',\"MCAP_Q\":'mq'})\n",
    "sedol_list=all_data['sedol'].unique().tolist()\n",
    "\n",
    "date_list=list(set(list(all_data['date'])))\n",
    "date_list.sort()\n",
    "\n",
    "dic_data = {k: v for k, v in all_data.groupby('date')}\n",
    "\n",
    "\n",
    "results_=pd.read_csv('data/results_template.csv')\n",
    "results_=results_.rename(columns={'DATE':'date','SEDOL':'sedol','WEIGHTS':'w','FOUR_WEEKLY_RETURN':'r'})\n",
    "results_['date']=pd.to_datetime(results_['date'])\n",
    "dic_results_={k: v for k, v in results_.groupby('date')}\n",
    "\n",
    "\n",
    "def preprocessing(date):\n",
    "    \n",
    "    using_dic = dic_data[pd.to_datetime(date)]\n",
    "    using_dic['index']=list(using_dic.index)\n",
    "\n",
    "    asset_list = []\n",
    "    for i in using_dic[\"sedol\"]:\n",
    "        asset_list.append(i)\n",
    "\n",
    "\n",
    "    dic_sedol_as = {using_dic[\"sedol\"][i] : using_dic[\"as\"][i] for i in using_dic.index}\n",
    "\n",
    "    dic_bench = {using_dic[\"sedol\"][i] : using_dic[\"bw\"][i] for i in using_dic.index}\n",
    "\n",
    "    dic_beta = {using_dic[\"sedol\"][i] : using_dic[\"beta\"][i] for i in using_dic.index}\n",
    "\n",
    "    dic_sector = {using_dic[\"sector\"][i] : [] for i in using_dic.index }\n",
    "\n",
    "    dic_MCAP = {using_dic[\"mq\"][i] : [] for i in using_dic.index}\n",
    "\n",
    "    for i in using_dic.index:\n",
    "        dic_sector[using_dic[\"sector\"][i]].append(using_dic[\"sedol\"][i])\n",
    "        dic_MCAP[using_dic[\"mq\"][i]].append(using_dic[\"sedol\"][i])\n",
    "\n",
    "\n",
    "    #risk:cov_mat\n",
    "    date_str=str(date)[:10]\n",
    "    risk_data=pd.read_csv('data/Riskmodels/cov_mat_%s.csv'%(date_str))\n",
    "    risk_sedol=risk_data['ROW_INDEX'].unique().tolist()\n",
    "    risk_mat = np.zeros((len(risk_sedol),len(risk_sedol)))\n",
    "    risk_mat[np.triu_indices(len(risk_sedol), 0)] = list(risk_data['VALUE'])\n",
    "    irows,icols = np.triu_indices(len(risk_sedol),0)\n",
    "    risk_mat[icols,irows]=risk_mat[irows,icols]\n",
    "    #         return risk_data,risk_sedol,risk_mat\n",
    "\n",
    "\n",
    "    dic_r={dic_results_[date][\"sedol\"][i] : dic_results_[date][\"r\"][i] for i in using_dic.index}\n",
    "\n",
    "    return using_dic,asset_list,dic_sedol_as,dic_bench,dic_beta,dic_sector,dic_MCAP,risk_sedol,risk_mat,dic_r\n",
    "\n",
    "print(\"complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete\n"
     ]
    }
   ],
   "source": [
    "def cal_obj(sol, risk_mat, as_) :\n",
    "\n",
    "    a = np.full((len(risk_mat[0]), len(risk_mat[0])), 5000)\n",
    "    risk_mat = risk_mat * a\n",
    "    sol_d = list(np.array(sol) - np.array(using_dic['bw']))\n",
    "    s_rr = np.dot(sol_d, risk_mat)\n",
    "    s_r = np.dot(s_rr, sol_d)\n",
    "    s_a = np.dot(sol_d, as_)\n",
    "    obj = s_r+s_a\n",
    "    return obj\n",
    "\n",
    "\n",
    "\n",
    "def select_candi(sol) :\n",
    "    \n",
    "    diff_sub = np.array([0]*len(as_), float)\n",
    "    diff_add = np.array([0]*len(as_), float)\n",
    "    candi = []\n",
    "    \n",
    "    if sum(sol) >= 50 :\n",
    "        for val in range(len(sol)) :\n",
    "            if sol[val] > 0. :\n",
    "                candi.append(val)\n",
    "        \n",
    "    else :\n",
    "        for i in range(len(sol)) :\n",
    "            if(sol[i] > 0) :\n",
    "                w = sol[i]\n",
    "                sol[i] = 0\n",
    "                diff_sub[i] = cal_obj(sol, risk_mat, as_)\n",
    "                if min(diff_sub[diff_sub>0]) == diff_sub[i] :\n",
    "                    for j in range(len(sol)) :\n",
    "                        if sol[j] == 0 :\n",
    "                            sol[j] = w\n",
    "                            diff_add[j] = cal_obj(sol, risk_mat, as_)\n",
    "                            sol[j] = 0\n",
    "                sol[i] = w\n",
    "        \n",
    "        sol[np.where(diff_sub == min(diff_sub[diff_sub>0]))[0][0]] = 0\n",
    "        sol[np.where(diff_add == min(diff_add[diff_add>0]))[0][0]] = 0.1\n",
    "        \n",
    "        for val in range(len(sol)) :\n",
    "            if sol[val] > 0. :\n",
    "                candi.append(val)\n",
    "        print(candi)\n",
    "\n",
    "    return candi\n",
    "\n",
    "\n",
    "\n",
    "def update(sol,lim_time,as_) :\n",
    "    start_time = time.time()\n",
    "    ex = inform.informs(10000, 10000, w_pre, O_scale,dic_sector,dic_bench,risk_sedol,dic_MCAP,dic_beta,alpha,risk_mat)\n",
    "    ex.set_omega(risk_mat)\n",
    "\n",
    "    new_list = []          \n",
    "    for k in risk_sedol :\n",
    "        new_list.append(sol[k])\n",
    "\n",
    "    result_list = []\n",
    "\n",
    "    while(True):\n",
    "\n",
    "        if time.time() - start_time > lim_time:\n",
    "            break\n",
    "        con = select_candi(new_list)\n",
    "        ex.set_con(cons=con)\n",
    "        new_list2 = []\n",
    "        new_list3 = []\n",
    "        try:\n",
    "            aabbaa = ex.solve(0.01)\n",
    "\n",
    "            if aabbaa != 0:\n",
    "                aaaa = aabbaa[0]\n",
    "                bbbb= aabbaa[1]\n",
    "                for k in risk_sedol :\n",
    "                    new_list2.append(aaaa[k])\n",
    "                for k in risk_sedol :\n",
    "                    new_list3.append(bbbb[k])\n",
    "                new_list = new_list2\n",
    "\n",
    "                result_list.append(aabbaa[2])\n",
    "\n",
    "            else:\n",
    "                print(\"TE infeasible\")\n",
    "        except:\n",
    "            print(\"no solution\")\n",
    "\n",
    "\n",
    "    return result_list\n",
    "\n",
    "def sample_Z(m, n):\n",
    "    return Variable(torch.Tensor(np.random.uniform(0., 1., size=[m, n])))\n",
    "\n",
    "        \n",
    "def xavier_init(size):\n",
    "    in_dim = size[0]\n",
    "    xavier_stddev = 1. / np.sqrt(in_dim / 2.)\n",
    "    return np.random.normal(size=size, scale=xavier_stddev)\n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self,  in_dim=10, hd_dim=50, out_dim=500):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        self.G_W1 = nn.Parameter(torch.from_numpy(xavier_init([in_dim, hd_dim])).float())\n",
    "        self.G_b1 = nn.Parameter(torch.from_numpy(np.zeros(shape=[hd_dim])).float())\n",
    "        \n",
    "    \n",
    "        self.G_W12 = nn.Parameter(torch.from_numpy(xavier_init([hd_dim, hd_dim])).float())\n",
    "        self.G_b12 = nn.Parameter(torch.from_numpy(np.zeros(shape=[hd_dim])).float())\n",
    "        \n",
    "        self.G_W13 = nn.Parameter(torch.from_numpy(xavier_init([hd_dim, hd_dim])).float())\n",
    "        self.G_b13 = nn.Parameter(torch.from_numpy(np.zeros(shape=[hd_dim])).float())\n",
    "\n",
    "        \n",
    "        self.G_W2 = nn.Parameter(torch.from_numpy(xavier_init([hd_dim, out_dim])).float())\n",
    "        self.G_b2 = nn.Parameter(torch.from_numpy(np.zeros(shape=[out_dim])).float())\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu( x @ self.G_W1 + self.G_b1)\n",
    "        x = F.relu( x @ self.G_W12 + self.G_b12)\n",
    "        x = F.relu( x @ self.G_W13 + self.G_b13)\n",
    "        x = x @ self.G_W2 + self.G_b2\n",
    "\n",
    "        return F.sigmoid(x*0.1)\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, in_dim=500,train=False):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.tot_infs = 0.0\n",
    "        self.tot_infs_nor = 0.0\n",
    "        self.train = train\n",
    "        self.x_threshold = 0.001\n",
    "        self.inf_scale = 100.0\n",
    "        self.Zstar = 1000\n",
    "        \n",
    "        self.in_dim = in_dim\n",
    "\n",
    "        np.random.seed(0)\n",
    "        self.Omega = Variable(torch.from_numpy(risk_mat)).float()\n",
    "\n",
    "        self.card_upper = 70.\n",
    "        self.card_lower = 60.\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        tot_infs = Variable(torch.zeros(x.size()[0]))\n",
    "        x_bw = Variable(torch.from_numpy(bw).float())\n",
    "        alp = Variable(torch.Tensor(alpha).float())   \n",
    "        bet = Variable(torch.Tensor(beta).float())\n",
    " \n",
    "        # (4)\n",
    "        tot_infs += F.relu(1. - torch.sum(x,1))\n",
    "        tot_infs += F.relu(torch.sum(x,1) - 1.)\n",
    "        \n",
    "        # (5)\n",
    "        tot_infs += F.relu(torch.abs(x-x_bw)@ Variable(torch.ones(self.in_dim))-0.05)\n",
    "\n",
    "        # (6)\n",
    "        for j in range(nbsector):\n",
    "            k= (x-x_bw) @ Variable(\n",
    "                torch.Tensor([1 if i in group_by_sector[j] else 0 for i in range(self.in_dim)]).float())  #sum\n",
    "            l = torch.abs(k)\n",
    "            tot_infs += F.relu(l - 0.1)\n",
    "            \n",
    "        # (7)\n",
    "        for j in range(nbmq):\n",
    "            k = (x-x_bw) @ Variable(\n",
    "                torch.Tensor([1 if i in group_by_mq[j] else 0 for i in range(self.in_dim)]).float())  #sum\n",
    "            l = torch.abs(k)\n",
    "            tot_infs += F.relu(l - 0.1)\n",
    "            \n",
    "        # (8)\n",
    "        k = (x - x_bw)@bet\n",
    "        l = torch.abs(k)\n",
    "        tot_infs += F.relu(l - 0.1)\n",
    "        \n",
    "        # (9) lb <= card(x) <= b\n",
    "        if self.train:\n",
    "            num_non_zeros = torch.sum(torch.tanh(x / self.x_threshold), 1)\n",
    "            tot_infs += F.relu(num_non_zeros - self.card_upper) + F.relu(self.card_lower - num_non_zeros)\n",
    "        else:\n",
    "            num_non_zeros = torch.sum(x.data>self.x_threshold, 1).float()\n",
    "            tot_infs += Variable(np.maximum(num_non_zeros - self.card_upper, 0) + np.maximum(self.card_lower - num_non_zeros, 0))\n",
    "    \n",
    "        \n",
    "        # (10)\n",
    "        l = 0.5*torch.sum(torch.abs(x - x_bw))\n",
    "        tot_infs += F.relu(0.6 - l)\n",
    "        #tot_infs += F.relu(l - 1.)\n",
    "    \n",
    "        \n",
    "        # (11) a<=dQd <= b\n",
    "        dQ = (x-x_bw) @ self.Omega\n",
    "        size_x = x.size()\n",
    "        dQd = torch.bmm(dQ.view(size_x[0],1,size_x[1]), (x-x_bw).view(size_x[0],size_x[1],1)).squeeze(1).squeeze(1)\n",
    "        tot_infs += F.relu(dQd - 0.01)\n",
    "        tot_infs += F.relu(0.0025 - dQd)\n",
    "        \n",
    "        \n",
    "        # min dQd + ad (<= Zstar)\n",
    "        l = (x-x_bw)@alp\n",
    "\n",
    "        MONTH =0\n",
    "        turnover=x_bw\n",
    "        \n",
    "        if MONTH > 0 :\n",
    "            tot_infs += (F.relu(100.*dQd - 100.*l -0.5*turnover - self.Zstar))\n",
    "            self.objs = 100.*dQd - 100.*l -0.5*turnover\n",
    "        else:\n",
    "            tot_infs += (F.relu(100.*dQd - 100.*l  - self.Zstar ))\n",
    "            self.objs = 100.*dQd - 100.*l\n",
    "        \n",
    "        \n",
    "        fea_probs = F.relu(1. - F.tanh(tot_infs/self.inf_scale))  \n",
    "\n",
    "        \n",
    "        return fea_probs\n",
    "        \n",
    "\n",
    "\n",
    "def GAN(rotation):\n",
    "    X_dim = nbasset\n",
    "    HL_dim = 50\n",
    "    Z_dim = 10\n",
    "\n",
    "    G = Generator(Z_dim, HL_dim, X_dim)\n",
    "\n",
    "    sample_D = Discriminator(X_dim, train=False)\n",
    "    train_D = Discriminator(X_dim, train=True)\n",
    "\n",
    "    G_solver = optim.Adam(G.parameters(), lr=1e-3)\n",
    "\n",
    "    mb_size = 128\n",
    "\n",
    "    best_obj = 100000.0\n",
    "    best_sols = []\n",
    "\n",
    "    losses = []\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    feasible_threshold = 0.95\n",
    "\n",
    "    adaptive_inf_scale = float(nbasset)\n",
    "\n",
    "    for it in range(rotation):\n",
    "        if it % 1000 == 0:\n",
    "            sample_noise = sample_Z(128, Z_dim)\n",
    "            samples = G(sample_noise)\n",
    "\n",
    "            sample_D.Zstar = best_obj\n",
    "            sample_D.inf_scale = adaptive_inf_scale\n",
    "\n",
    "            sample_D_values = sample_D(samples).data.numpy()\n",
    "            sample_obj_values = sample_D.objs.data.numpy()\n",
    "\n",
    "            fea_sample_obj_values = sample_obj_values[sample_D_values > feasible_threshold]\n",
    "            sols = samples.data.numpy()[sample_D_values > feasible_threshold]\n",
    "\n",
    "            if len(fea_sample_obj_values > 0):\n",
    "                best_idx = np.argmin(fea_sample_obj_values)\n",
    "                if np.min(fea_sample_obj_values) < best_obj:\n",
    "                    best_obj = np.minimum(fea_sample_obj_values[best_idx], best_obj)\n",
    "                    best_sols.append(sols[best_idx])\n",
    "\n",
    "        z = Variable(torch.randn(mb_size, Z_dim))\n",
    "\n",
    "        train_D.Zstar = best_obj\n",
    "        train_D.inf_scale = adaptive_inf_scale\n",
    "\n",
    "        G_loss = -torch.mean(torch.log(train_D(G(z))))\n",
    "\n",
    "        G.zero_grad()\n",
    "        G_loss.backward()\n",
    "        G_solver.step()\n",
    "\n",
    "        \n",
    "    return best_sols, sols,fea_sample_obj_values\n",
    "\n",
    "def GAN_reulst(best_sols, sols,fea_sample_obj_values):    \n",
    "    good_sols=np.argsort(fea_sample_obj_values)[:10]\n",
    "    card_list=[list(np.where(sols[i]>0.001)[0]) for i in range(len(good_sols))]\n",
    "    card_freq=np.zeros(nbasset)\n",
    "    for i in range(len(card_list)):\n",
    "        for j in card_list[i]:\n",
    "            card_freq[j]+=1\n",
    "    best=np.argsort(sum(sols))[::-1][:len(card_freq[card_freq>len(card_list)-5])]\n",
    "    bestsol=np.where(best_sols[0]>0.001)[0]\n",
    "    return best,bestsol\n",
    "\n",
    "def init_cplex(risk_mat,risk_sedol):\n",
    "    sedol_var_list =[]\n",
    "    for i in risk_sedol:\n",
    "        sedol_var_list.append(\"d\"+str(i))\n",
    "\n",
    "    for i in risk_sedol:\n",
    "        sedol_var_list.append(\"q\"+str(i))\n",
    "\n",
    "    sedol_var_list.append(\"assum\")\n",
    "    #global alpha\n",
    "    alpha = []\n",
    "    for i in risk_sedol:\n",
    "        alpha.append(-100000.*dic_sedol_as[i])\n",
    "\n",
    "    qmat=[]\n",
    "    for i in range(len(risk_mat)):\n",
    "        qmat_1=[]\n",
    "        qmat_1.append(sedol_var_list)\n",
    "        new_risk_mat=[]\n",
    "        for j in risk_mat[i]:\n",
    "            new_risk_mat.append(10000*j)\n",
    "        for j in risk_mat[i]:\n",
    "            new_risk_mat.append(0)\n",
    "        new_risk_mat.append(0)\n",
    "        qmat_1.append(new_risk_mat)\n",
    "        qmat.append(qmat_1)\n",
    "\n",
    "    for i in range(len(risk_mat)):\n",
    "        qmat_1=[]\n",
    "        qmat_1.append(sedol_var_list)\n",
    "        new_risk_mat=[]\n",
    "        for j in risk_mat[i]:\n",
    "            new_risk_mat.append(0)\n",
    "        for j in risk_mat[i]:\n",
    "            new_risk_mat.append(0)\n",
    "        new_risk_mat.append(0)\n",
    "        qmat_1.append(new_risk_mat)\n",
    "        qmat.append(qmat_1)\n",
    "\n",
    "    for i in range(1):\n",
    "        qmat_1=[]\n",
    "        qmat_1.append(sedol_var_list)\n",
    "        new_risk_mat=[]\n",
    "        for j in risk_mat[i]:\n",
    "            new_risk_mat.append(0)\n",
    "        for j in risk_mat[i]:\n",
    "            new_risk_mat.append(0)\n",
    "        new_risk_mat.append(0)\n",
    "        qmat_1.append(new_risk_mat)\n",
    "        qmat.append(qmat_1)\n",
    "\n",
    "    q_con1 = []\n",
    "    q_con2 = []\n",
    "    q_val = []\n",
    "\n",
    "\n",
    "    for i in range(len((risk_mat[0]))):\n",
    "        for j in range(len(risk_mat[0])):\n",
    "            if j >= i:\n",
    "                q_con1.append(i)\n",
    "                q_con2.append(j)\n",
    "                if i == j:\n",
    "                    ex_list = list(risk_mat[i])\n",
    "                    q_val.append(0.5*ex_list[j]*10000)\n",
    "                else:\n",
    "                    ex_list = list(risk_mat[i])\n",
    "                    q_val.append(ex_list[j]*10000)\n",
    "\n",
    "    Q_con = []\n",
    "    Q_con.append(q_con1)\n",
    "    Q_con.append(q_con2)\n",
    "    Q_con.append(q_val)\n",
    "    \n",
    "    return Q_con, qmat, alpha\n",
    "\n",
    "print(\"complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "solve!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPXPARAM_TimeLimit                               10\n",
      "CPXPARAM_Read_DataCheck                          1\n",
      "CPXPARAM_Threads                                 1\n",
      "CPXPARAM_Read_APIEncoding                        \"UTF-8\"\n",
      "CPXPARAM_MIP_Strategy_CallbackReducedLP          0\n",
      "Tried aggregator 2 times.\n",
      "MIQCP Presolve eliminated 1486 rows and 2 columns.\n",
      "MIQCP Presolve modified 1476 coefficients.\n",
      "Aggregator did 58 substitutions.\n",
      "Reduced MIQCP has 1941 rows, 2839 columns, and 197656 nonzeros.\n",
      "Reduced MIQCP has 492 binaries, 0 generals, 0 SOSs, and 0 indicators.\n",
      "Reduced MIQCP has 2 quadratic constraints.\n",
      "Presolve time = 0.18 sec. (431.54 ticks)\n",
      "Probing time = 0.04 sec. (21.83 ticks)\n",
      "MIP emphasis: balance optimality and feasibility.\n",
      "MIP search method: dynamic search.\n",
      "Parallel mode: none, using 1 thread.\n",
      "Root relaxation solution time = 0.03 sec. (45.53 ticks)\n",
      "\n",
      "        Nodes                                         Cuts/\n",
      "   Node  Left     Objective  IInf  Best Integer    Best Bound    ItCnt     Gap\n",
      "\n",
      "      0     0       -1.5747     0                    -13.9841      750         \n",
      "      0     0       -1.5630     0                     Cone: 1      779         \n",
      "      0     0       -1.5538     0                     Cone: 2      799         \n",
      "      0     0       -1.5499     2                     Cone: 3      814         \n",
      "      0     0       -1.5489     0                     Cone: 4      819         \n",
      "      0     0       -1.5407     0                     Cone: 5      851         \n",
      "      0     0       -1.5347     0                     Cone: 6      874         \n",
      "*     0     0      integral     0        6.2350       -1.5275      907  124.50%\n",
      "*     0+    0                            6.2331       -1.5200           124.39%\n",
      "*     0+    0                            5.9339       -1.5200           125.62%\n",
      "*     0     0      integral     0        4.4733       -1.5181     1035  133.94%\n",
      "      0     2       -1.3786     0        4.4733       Cone: 7     1035  130.82%\n",
      "Elapsed time = 8.81 sec. (18497.70 ticks, tree = 0.01 MB, solutions = 5)\n",
      "      1     1        cutoff              4.4733       -1.3786     1035  130.82%\n",
      "\n",
      "Cone linearizations applied:  15\n",
      "\n",
      "Root node processing (before b&c):\n",
      "  Real time             =    3.59 sec. (8633.10 ticks)\n",
      "Sequential b&c:\n",
      "  Real time             =    6.47 sec. (12268.11 ticks)\n",
      "                          ------------\n",
      "Total (root+branch&cut) =   10.05 sec. (20901.21 ticks)\n",
      "107\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'w_pre' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-03861c1d0d7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0mas_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0musing_dic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'as'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msol\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m50.\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mas_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"------objective value 변화------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-fb6c2f324192>\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(sol, lim_time, as_)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msol\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlim_time\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mas_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     \u001b[0mex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minforms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_pre\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mO_scale\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdic_sector\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdic_bench\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrisk_sedol\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdic_MCAP\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdic_beta\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrisk_mat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m     \u001b[0mex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_omega\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrisk_mat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'w_pre' is not defined"
     ]
    }
   ],
   "source": [
    "#for i in date: 이런식으로 하되 evaluation criteria 는 아직 반영안함..!\n",
    "\n",
    "\n",
    "############################################\n",
    "date=date_list[0]\n",
    "init_set='cplex' #initial set by GAN, cplex, random\n",
    "\n",
    "c_time = 10. #cplex time for initial set\n",
    "gan_rot = 2000 #GAN epoch size for initial set\n",
    "############################################\n",
    "\n",
    "\n",
    "#preprocessing\n",
    "using_dic,asset_list,dic_sedol_as,dic_bench,dic_beta,dic_sector,dic_MCAP,risk_sedol,risk_mat,dic_r=preprocessing(date)\n",
    "\n",
    "\n",
    "#set initial cardinality\n",
    "if init_set=='cplex':\n",
    "    Q_con, qmat, alpha = init_cplex(risk_mat,risk_sedol)\n",
    "    sol = portfolio(sector=dic_sector,bench=dic_bench,asset=risk_sedol,MCAPQ=dic_MCAP,beta=dic_beta,alpha=alpha,qmat=qmat, Q_con=Q_con,multiple=10000,time_init=c_time)[0]\n",
    "\n",
    "elif init_set=='GAN':\n",
    "    \n",
    "    bw=list(using_dic['bw'])\n",
    "    bw=np.array(bw)\n",
    "\n",
    "    beta=list(using_dic['beta'])\n",
    "    beta=np.array(beta)\n",
    "\n",
    "    alpha=list(using_dic['as'])\n",
    "    alpha=np.array(alpha)\n",
    "\n",
    "    sector_set = set(list(using_dic['sector']))\n",
    "    sector_list = list(using_dic['sector'])\n",
    "\n",
    "    gbs=using_dic[['sector', 'index']].apply(tuple, axis=1)\n",
    "    group_by_sector = [[y[1] for y in gbs if y[0]==x] for x in sector_set]\n",
    "\n",
    "    mq_list=list(using_dic['mq'])\n",
    "    mq_set=set(list(using_dic['mq']))\n",
    "\n",
    "    gbm=using_dic[['mq', 'index']].apply(tuple, axis=1)\n",
    "    group_by_mq = [[y[1] for y in gbm if y[0]==x] for x in mq_set]\n",
    "\n",
    "    nbasset=len(bw)\n",
    "    nbsector=len(sector_set)\n",
    "    nbmq=len(mq_set)\n",
    "\n",
    "    best_sols, sols,fea_sample_obj_values=GAN(gan_rot)\n",
    "    best,bestsol=GAN_reulst(best_sols, sols,fea_sample_obj_values)\n",
    "\n",
    "    print(len(best))\n",
    "\n",
    "\n",
    "    sol={}\n",
    "    for i in range(len(risk_sedol)):\n",
    "        if i in best: sol[risk_sedol[i]]=1.\n",
    "        else: sol[risk_sedol[i]]=0.\n",
    "\n",
    "elif init_set=='random':\n",
    "    r=list(set(list(np.random.randint(len(risk_sedol),size=70))))\n",
    "    sol={}\n",
    "    for i in range(len(risk_sedol)):\n",
    "        if i in r: sol[risk_sedol[i]]=1.\n",
    "        else: sol[risk_sedol[i]]=0.\n",
    "\n",
    "\n",
    "\n",
    "# solve & update\n",
    "\n",
    "as_ = using_dic['as']\n",
    "result = update(sol,50.,as_)\n",
    "\n",
    "print(\"------objective value 변화------\")\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Evaluation Criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def turnover(w_dic,w_dic2):\n",
    "    pre_list = set(list(w_dic.keys()))\n",
    "\n",
    "    rotp_t0 = 0\n",
    "\n",
    "    for i in risk_sedol:\n",
    "        rotp_t0 += w_dic[i]*dic_sedol_as[i]\n",
    "        \n",
    "        \n",
    "    w_i_pre = {}\n",
    "    \n",
    "    w_pre = 0\n",
    "    \n",
    "    \n",
    "    for i in risk_sedol:\n",
    "        w_pre += w_dic[i]*(dic_sedol_as[i]+1)\n",
    "\n",
    "        \n",
    "        \n",
    "    w_i_pre_sum = 0\n",
    "\n",
    "    for i in risk_sedol:\n",
    "        w_i_pre.update({i:(w_dic[i]*(dic_sedol_as[i]+1))/w_pre})\n",
    "        w_i_pre_sum += (w_dic[i]*(dic_sedol_as[i]+1))/w_pre\n",
    "\n",
    "        \n",
    "\n",
    "   \n",
    "        \n",
    "        \n",
    "    pre_list2 = set(list(w_dic2.keys()))\n",
    "\n",
    "    turnover = 0\n",
    "\n",
    "    add_key_1 = pre_list-pre_list2\n",
    "    add_key_2 = pre_list2-pre_list\n",
    "\n",
    "\n",
    "    for i in add_key_2:\n",
    "        w_dic.update({i:0})\n",
    "\n",
    "    for i in add_key_1:\n",
    "        w_dic2.update({i:0})\n",
    "\n",
    "    pre_list.union(pre_list2)\n",
    "\n",
    "    for i in pre_list:\n",
    "        turnover += abs(w_dic2[i]-w_i_pre[i])\n",
    "\n",
    "    rOTP = 0\n",
    "\n",
    "    for i in dic_sedol_as.keys():\n",
    "        rOTP += w_dic2[i]*dic_sedol_as2[i]\n",
    "\n",
    "    r_Txadj_t = rOTP - turnover*0.5\n",
    "    \n",
    "    result=[]\n",
    "    result.append(turnover,rOTP,r_Txadj_t)\n",
    "    result.append(w_i_pre_sum)\n",
    "    \n",
    "    print(\"turnover : \" + str(turnover))\n",
    "    print(\"r_OTP : \" + str(rOTP))\n",
    "    print(\"r_Txadj_t : \" + str(r_Txadj_t))\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "def IR_TE(result,bench_t):\n",
    "    cal1 = 1\n",
    "    cal2 = 1\n",
    "    list_std=np.array([])\n",
    "\n",
    "    for i in range(len(result)):\n",
    "        cal1 = cal1*(1+result[i])\n",
    "        cal2 = cal2*(1+bench_t[i])\n",
    "        list_std = np.append(list_std,resultp[i]-bench_t[i])\n",
    "    \n",
    "    IR = (cal1-cal2)/np.std(list_std)\n",
    "    \n",
    "    TE = math.sqrt(13)*np.std(list_std)\n",
    "    \n",
    "    result = []\n",
    "    \n",
    "    result.append(IR,TE)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def R_SR(result,bench,n):\n",
    "    R_CUM = 1\n",
    "    B_CUM = 1\n",
    "    for i in range(len(result)):\n",
    "        R_CUM = R_CUM*(1+result[t])\n",
    "        \n",
    "    for i in range(len(bench)):\n",
    "        B_CUM = B_CUM*(1+bench[t])\n",
    "    \n",
    "    R_CUM = R_CUM-1\n",
    "    \n",
    "    B_CUM = B_CUM-1\n",
    "    \n",
    "    R_ANN = (1+R_CUM)**(13/n) - 1\n",
    "    \n",
    "    B_ANN = (1+B_CUM)**(13/n) - 1\n",
    "    \n",
    "    R_EXAN = R_ANN-B_ANN\n",
    "    \n",
    "    r_t = np.array(result)\n",
    "    \n",
    "    SR = R_CUM/np.std(r_t)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ipy parallel 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: MacOSX\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import ipyparallel as ipp\n",
    "%matplotlib\n",
    "\n",
    "rc = ipp.Client()\n",
    "# print(rc.ids)\n",
    "dv = rc[:]\n",
    "# dv.block=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AsyncResult: execute>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# with dv.sync_imports():\n",
    "#     import class_informs as inform\n",
    "    \n",
    "dv.execute('import class_informs as inform')\n",
    "dv.execute('ex = inform.informs(10000)')\n",
    "dv.execute('ex.set_omega(risk_mat)')\n",
    "\n",
    "# os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete\n"
     ]
    }
   ],
   "source": [
    "def cp(con) :\n",
    "    new_list2 = []\n",
    "    ex.set_con(cons=con)\n",
    "    print(\"aaaaaaaaaaaaaaaaaaa\")\n",
    "#     try :\n",
    "    aabbaa = 1\n",
    "    aabbaa = ex.solve(0.01)\n",
    "    if aabbaa != 0:\n",
    "        aaaa = aabbaa[0]\n",
    "        bbbb= aabbaa[1]\n",
    "        for k in risk_sedol :\n",
    "            new_list2.append(aaaa[k])\n",
    "\n",
    "        result_list.append(aabbaa[2])\n",
    "        return aabbaa[2]\n",
    "    else:\n",
    "        print(\"TE infeasible\")\n",
    "        return aabbaa\n",
    "#     except:\n",
    "#         print(\"no solution\")\n",
    "#         return 1\n",
    "    return 2\n",
    "\n",
    "\n",
    "def update(sol,lim_time,as_) :\n",
    "    start_time = time.time()\n",
    "\n",
    "    new_list = []          \n",
    "    for k in risk_sedol :\n",
    "        new_list.append(sol[k])\n",
    "\n",
    "    result_list = []\n",
    "\n",
    "    while(True):\n",
    "\n",
    "        if time.time() - start_time > lim_time:\n",
    "            break\n",
    "        con = select_candi(new_list)\n",
    "        con11 = [con]*4\n",
    "        print(\"work???\")\n",
    "        print(dv)\n",
    "        axz = dv.map(cp, con11)\n",
    "#         print(list(axz))\n",
    "        print(\"work!!!\")\n",
    "#         print(axz)\n",
    "        axz.wait()\n",
    "        print(axz.get())\n",
    "#         print(list(axz))\n",
    "        \n",
    "#         adsadsadadasdasd\n",
    "        axz.wait()\n",
    "\n",
    "    return result_list\n",
    "\n",
    "print(\"complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n",
      "work???\n",
      "<DirectView [0, 1, 2, 3,...]>\n",
      "work!!!\n",
      "[0, 0, 0, 0]\n",
      "ok\n",
      "work???\n",
      "<DirectView [0, 1, 2, 3,...]>\n",
      "work!!!\n",
      "[0, 0, 0, 0]\n",
      "ok\n",
      "work???\n",
      "<DirectView [0, 1, 2, 3,...]>\n",
      "work!!!\n",
      "[0, 0, 0, 0]\n",
      "ok\n",
      "work???\n",
      "<DirectView [0, 1, 2, 3,...]>\n",
      "work!!!\n",
      "[0, 0, 0, 0]\n",
      "ok\n",
      "work???\n",
      "<DirectView [0, 1, 2, 3,...]>\n",
      "work!!!\n",
      "[0, 0, 0, 0]\n",
      "ok\n",
      "work???\n",
      "<DirectView [0, 1, 2, 3,...]>\n",
      "work!!!\n",
      "[0, 0, 0, 0]\n",
      "ok\n",
      "work???\n",
      "<DirectView [0, 1, 2, 3,...]>\n",
      "work!!!\n",
      "[0, 0, 0, 0]\n",
      "ok\n",
      "work???\n",
      "<DirectView [0, 1, 2, 3,...]>\n",
      "work!!!\n",
      "[0, 0, 0, 0]\n",
      "ok\n",
      "work???\n",
      "<DirectView [0, 1, 2, 3,...]>\n",
      "work!!!\n",
      "[0, 0, 0, 0]\n",
      "ok\n",
      "work???\n",
      "<DirectView [0, 1, 2, 3,...]>\n",
      "work!!!\n",
      "[0, 0, 0, 0]\n",
      "ok\n",
      "work???\n",
      "<DirectView [0, 1, 2, 3,...]>\n",
      "work!!!\n",
      "[0, 0, 0, 0]\n",
      "ok\n",
      "work???\n",
      "<DirectView [0, 1, 2, 3,...]>\n",
      "work!!!\n",
      "[0, 0, 0, 0]\n",
      "ok\n",
      "work???\n",
      "<DirectView [0, 1, 2, 3,...]>\n",
      "work!!!\n",
      "[0, 0, 0, 0]\n",
      "ok\n",
      "work???\n",
      "<DirectView [0, 1, 2, 3,...]>\n",
      "work!!!\n",
      "[0, 0, 0, 0]\n",
      "ok\n",
      "work???\n",
      "<DirectView [0, 1, 2, 3,...]>\n",
      "work!!!\n",
      "[0, 0, 0, 0]\n",
      "ok\n",
      "work???\n",
      "<DirectView [0, 1, 2, 3,...]>\n",
      "work!!!\n",
      "[0, 0, 0, 0]\n",
      "ok\n",
      "work???\n",
      "<DirectView [0, 1, 2, 3,...]>\n",
      "work!!!\n",
      "[0, 0, 0, 0]\n",
      "ok\n",
      "work???\n",
      "<DirectView [0, 1, 2, 3,...]>\n",
      "work!!!\n",
      "[0, 0, 0, 0]\n",
      "ok\n",
      "work???\n",
      "<DirectView [0, 1, 2, 3,...]>\n",
      "work!!!\n",
      "[0, 0, 0, 0]\n",
      "ok\n",
      "work???\n",
      "<DirectView [0, 1, 2, 3,...]>\n",
      "work!!!\n",
      "[0, 0, 0, 0]\n",
      "ok\n",
      "work???\n",
      "<DirectView [0, 1, 2, 3,...]>\n",
      "work!!!\n",
      "[0, 0, 0, 0]\n",
      "ok\n",
      "work???\n",
      "<DirectView [0, 1, 2, 3,...]>\n",
      "work!!!\n",
      "[0, 0, 0, 0]\n",
      "ok\n",
      "work???\n",
      "<DirectView [0, 1, 2, 3,...]>\n",
      "work!!!\n",
      "[0, 0, 0, 0]\n",
      "ok\n",
      "work???\n",
      "<DirectView [0, 1, 2, 3,...]>\n",
      "work!!!\n",
      "[0, 0, 0, 0]\n",
      "ok\n",
      "work???\n",
      "<DirectView [0, 1, 2, 3,...]>\n",
      "work!!!\n",
      "[0, 0, 0, 0]\n",
      "ok\n",
      "work???\n",
      "<DirectView [0, 1, 2, 3,...]>\n",
      "work!!!\n",
      "[0, 0, 0, 0]\n",
      "ok\n",
      "work???\n",
      "<DirectView [0, 1, 2, 3,...]>\n",
      "work!!!\n",
      "[0, 0, 0, 0]\n",
      "ok\n",
      "work???\n",
      "<DirectView [0, 1, 2, 3,...]>\n",
      "work!!!\n",
      "[0, 0, 0, 0]\n",
      "ok\n",
      "work???\n",
      "<DirectView [0, 1, 2, 3,...]>\n",
      "work!!!\n",
      "[0, 0, 0, 0]\n",
      "ok\n",
      "work???\n",
      "<DirectView [0, 1, 2, 3,...]>\n",
      "work!!!\n",
      "[0, 0, 0, 0]\n",
      "ok\n",
      "work???\n",
      "<DirectView [0, 1, 2, 3,...]>\n",
      "work!!!\n",
      "[0, 0, 0, 0]\n",
      "ok\n",
      "work???\n",
      "<DirectView [0, 1, 2, 3,...]>\n",
      "work!!!\n",
      "[0, 0, 0, 0]\n",
      "ok\n",
      "work???\n",
      "<DirectView [0, 1, 2, 3,...]>\n",
      "work!!!\n",
      "[0, 0, 0, 0]\n",
      "ok\n",
      "work???\n",
      "<DirectView [0, 1, 2, 3,...]>\n",
      "work!!!\n",
      "[0, 0, 0, 0]\n",
      "ok\n",
      "work???\n",
      "<DirectView [0, 1, 2, 3,...]>\n",
      "work!!!\n",
      "[0, 0, 0, 0]\n",
      "------objective value 변화------\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "#for i in date: 이런식으로 하되 evaluation criteria 는 아직 반영안함..!\n",
    "\n",
    "\n",
    "############################################\n",
    "date=date_list[0]\n",
    "init_set='cpex' #initial set by GAN, cplex, random\n",
    "\n",
    "c_time = 10. #cplex time for initial set\n",
    "gan_rot = 2000 #GAN epoch size for initial set\n",
    "############################################\n",
    "\n",
    "\n",
    "#preprocessing\n",
    "using_dic,asset_list,dic_sedol_as,dic_bench,dic_beta,dic_sector,dic_MCAP,risk_sedol,risk_mat,dic_r=preprocessing(date)\n",
    "\n",
    "\n",
    "if init_set=='random':\n",
    "    r=list(set(list(np.random.randint(len(risk_sedol),size=70))))\n",
    "    sol={}\n",
    "    for i in range(len(risk_sedol)):\n",
    "        if i in r: sol[risk_sedol[i]]=1.\n",
    "        else: sol[risk_sedol[i]]=0.\n",
    "\n",
    "\n",
    "\n",
    "# solve & update\n",
    "\n",
    "as_ = using_dic['as']\n",
    "result = update(sol,10.,as_)\n",
    "\n",
    "print(\"------objective value 변화------\")\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
