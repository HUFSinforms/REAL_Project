{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from concurrent import futures\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "import pandas_datareader.data as web\n",
    "from pandas_datareader import data\n",
    "\n",
    "import time,datetime\n",
    "import glob\n",
    "import fix_yahoo_finance as yf\n",
    "yf.pdr_override()\n",
    "\n",
    "\n",
    "from informs import portfolio\n",
    "import class_informs as inform\n",
    "import generator\n",
    "import discriminator\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import math\n",
    "import random as ran\n",
    "from scipy.stats import truncnorm\n",
    "\n",
    "import cmath\n",
    "\n",
    "import re\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SP500=pd.read_csv('data/s&p500.csv')\n",
    "SP100=pd.read_csv('data/s&p100.csv')\n",
    "SP400=pd.read_csv('data/s&p400.csv', encoding= \"ISO-8859-1\")\n",
    "SP400=SP400.rename(columns={'Ticker Symbol' : 'Symbol'})\n",
    "\n",
    "DAX=pd.read_csv('data/DAX.csv')\n",
    "DAX=DAX.rename(columns={'Ticker symbol.1' : 'Symbol'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_stockdata(stocks,start_date,end_date):\n",
    "    \n",
    "    fail_names =[] \n",
    "\n",
    "    df=pd.DataFrame()\n",
    "    \n",
    "    for stock in stocks:\n",
    "        try:\n",
    "            stock_df = data.get_data_yahoo(stock, start_date, end_date)\n",
    "            stock_df['Name'] = stock\n",
    "            df=df.append(stock_df)\n",
    "        except:\n",
    "            print('bad: %s' % (stock))\n",
    "            fail_names=fail_names.append(stock)\n",
    "\n",
    "            \n",
    "    return df,fail_names\n",
    "\n",
    "\n",
    "def bench(df,NEW_stocks):\n",
    "        \n",
    "    THIS=df[df.index==df.index[-1]]\n",
    "\n",
    "    THIS['tot_market']=THIS['Close']*THIS['Volume']\n",
    "    THIS['bench']=THIS['tot_market']/THIS['tot_market'].sum()\n",
    "\n",
    "    dic_bench={}\n",
    "    for i in list(THIS['Name']):\n",
    "        dic_bench[i]=float(THIS[THIS['Name']==i]['bench'])\n",
    "\n",
    "    return dic_bench,THIS\n",
    "\n",
    "\n",
    "\n",
    "def sector_mcapq(THIS):\n",
    "        \n",
    "    INFO=pd.read_csv('data/s&p500 list.csv')\n",
    "    INFO=INFO.rename(columns={'Ticker symbol' : 'Name'})\n",
    "\n",
    "\n",
    "    THIS=pd.merge(THIS, INFO, how='left')\n",
    "    THIS=THIS.rename(columns={'GICS_Sector' : 'Sector'})\n",
    "\n",
    "    THIS['rank'] = THIS['bench'].rank(ascending=0,method='min')\n",
    "    THIS['mcapq'] = np.where(THIS['rank']<=100, '1', np.where(THIS['rank']<=200, '2', np.where(THIS['rank']<=300, '3', np.where(THIS['rank']<=400, '4', '5'))))\n",
    "\n",
    "    \n",
    "    dic_sector = {THIS[\"Sector\"][i] : [] for i in THIS.index }\n",
    "\n",
    "    dic_MCAP = {THIS[\"mcapq\"][i] : [] for i in THIS.index}\n",
    "\n",
    "    for i in THIS.index:\n",
    "        dic_sector[THIS[\"Sector\"][i]].append(THIS[\"Name\"][i])\n",
    "        dic_MCAP[THIS[\"mcapq\"][i]].append(THIS[\"Name\"][i])\n",
    "    THIS['index']=list(THIS.index)\n",
    "    \n",
    "    return dic_sector,dic_MCAP,THIS\n",
    "        \n",
    "        \n",
    "def omega_covariances(prices):\n",
    "    prices =np.matrix(prices)\n",
    "    rows, cols = prices.shape\n",
    "    returns = np.empty([rows, cols - 1])\n",
    "    for r in range(rows):\n",
    "        for c in range(cols - 1):\n",
    "            p0, p1 = prices[r, c], prices[r, c + 1]\n",
    "            returns[r, c] = (p1 / p0) - 1\n",
    "    covars = np.cov(returns)\n",
    "    covars = covars * len(prices[0]) \n",
    "    return covars\n",
    "\n",
    "\n",
    "def alpha_return(stocks,start_date,end_date):\n",
    "    \n",
    "    close = pd.DataFrame()\n",
    "    fail_names=[]\n",
    "\n",
    "    for stock in stocks:\n",
    "        try:\n",
    "            close[stock] =  data.get_data_yahoo(stock, start_date, end_date)['Adj Close']\n",
    "        except:\n",
    "            fail_names.append(stock)\n",
    "\n",
    "    daily_simple_returns = close.pct_change()\n",
    "    annual_returns = daily_simple_returns.mean() * len(close)\n",
    "    \n",
    "    return close,annual_returns,fail_names\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "[*********************100%***********************]  1 of 1 downloaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yerin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/yerin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "#Data Setting\n",
    "start_date = '2017-02-16'\n",
    "end_date = '2018-02-15'\n",
    "stocks=list(DAX['Symbol'])\n",
    "\n",
    "\n",
    "#Data Loading\n",
    "df,fail_name=get_stockdata(stocks,start_date,end_date)\n",
    "df.to_csv('./data/DAX_df.csv')\n",
    "\n",
    "\n",
    "#Omega\n",
    "prices=list(df.groupby('Name')['Close'].apply(list))\n",
    "date_len=len(df.index.unique().tolist())\n",
    "for i in range(len(prices)):\n",
    "    if len(prices[i]) != date_len:\n",
    "        prices[i].extend([prices[i][-1]]*(date_len-len(prices[i])))\n",
    "        \n",
    "risk_mat = omega_covariances(prices)\n",
    "NEW_stocks=list(df.groupby('Name')['Close'].describe().index)\n",
    "        #risk_sedol->NEW_stocks\n",
    "\n",
    "#Alpha\n",
    "close,dic_alpha,fail_names2 = alpha_return(NEW_stocks,start_date,end_date)\n",
    "        #dic_sedol_as->dic_alpha    \n",
    "    \n",
    "\n",
    "#Bench Weight\n",
    "dic_bench,THIS = bench(df,NEW_stocks)\n",
    "\n",
    "\n",
    "#sector, MCAPQ\n",
    "dic_sector,dic_MCAP,THIS = sector_mcapq(THIS)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('all_data_DAX.txt', 'wb') as f:\n",
    "    pickle.dump(risk_mat, f)\n",
    "    pickle.dump(NEW_stocks, f)\n",
    "    pickle.dump(close, f)\n",
    "    pickle.dump(dic_alpha, f)\n",
    "    pickle.dump(dic_bench, f)\n",
    "    pickle.dump(dic_sector, f)\n",
    "    pickle.dump(dic_MCAP, f)\n",
    "    pickle.dump(THIS, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
